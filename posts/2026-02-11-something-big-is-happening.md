---
title: "Something Big Is Happening — Matt Shumer's Viral Wake-Up Call"
date: 2026-02-11
tags: [ai, analysis, opinion, future-of-work]
---

Matt Shumer's article "[Something Big Is Happening](https://x.com/mattshumer_/status/2021256989876109403)" hit 31 million views in 22 hours. 92,000 bookmarks. 51,000 likes. It's the kind of viral moment that usually requires celebrity drama or a market crash — and instead it's a 3,000-word essay about AI from a startup founder most people had never heard of.

That itself is a signal worth paying attention to.

## The Core Thesis

Shumer draws a parallel to February 2020: the moment before COVID when most people weren't paying attention, dismissing early warnings as overblown. He argues we're in that same phase now with AI — except what's coming is "much, much bigger."

His evidence is personal and specific:

> "I am no longer needed for the actual technical work of my job. I describe what I want built, in plain English, and it just... appears. Not a rough draft I need to fix. The finished thing."

He describes telling AI to build an app, walking away for four hours, and coming back to find it done — including the AI opening the app itself, clicking through buttons, testing features, and iterating until it's satisfied. His Monday this week.

The February 5th releases of GPT-5.3 Codex and Claude Opus 4.6 were, in his telling, the moment "something clicked." The models now have something that feels like *judgment* and *taste* — the intuitive sense of knowing what the right call is that humans always said AI would never have.

## The Pace of Change

Shumer cites METR's measurements of AI capability: how long can a model work independently on real tasks without human help?

- A year ago: ~10 minutes
- Then: 1 hour
- Then: several hours
- November 2025 (Claude Opus 4.5): ~5 hours
- Doubling time: 4-7 months

Extrapolate that curve and you get AI that can work independently for *days* within a year. *Weeks* within two. *Month-long projects* within three.

And here's the kicker: OpenAI's technical documentation for GPT-5.3 Codex included this line:

> "GPT-5.3-Codex is our first model that was instrumental in creating itself. The Codex team used early versions to debug its own training, manage its own deployment, and diagnose test results and evaluations."

The AI helped build itself. The feedback loop has started.

## My Take: Directionally Right, Metaphor Wrong

I agree with the core thesis. The gap between public perception and current AI capability is enormous and dangerous. The people dismissing this haven't used the current models, or they're evaluating based on 2024 experiences that are no longer relevant.

But I think the February 2020 parallel is the wrong metaphor.

**COVID was a shock.** Three weeks of total upheaval, then a new normal. The timeline was compressed, chaotic, and largely outside individual control.

**AI is more like January 2007 — the iPhone launch.** 

When Steve Jobs unveiled the iPhone, most people thought it was a nice gadget for Apple fans. Blackberry executives laughed. Nokia's market share was 50%. It took 10 years for the full transformation to play out: app stores, Uber, Instagram, the death of point-and-shoot cameras, the newspaper industry, taxi medallions, retail shopping, human attention itself.

The iPhone didn't change everything in three weeks. It changed everything over ten years — but the people who understood what was happening *on day one* had a decade-long head start.

That's where we are with AI. Not a three-week disruption. A ten-year transformation that's already started, where the early adopters have a compounding advantage.

## What Shumer Gets Right

**The free tier trap.** Most people are using free ChatGPT, which is over a year behind the paid models. "Judging AI based on free-tier ChatGPT is like evaluating smartphones by using a flip phone." This is completely accurate.

**The "briefly window" thesis.** Right now, most people at most companies are still ignoring this. The person who walks in and says "I used AI to do this in an hour instead of three days" is the most valuable person in the room. That window won't stay open long.

**The advice to have no ego about it.** The people who will struggle most are the ones who refuse to engage — who feel that using AI diminishes their expertise, who assume their field is special and immune. It's not.

## What I'd Add

**The disruption is uneven.** Some jobs get augmented (lawyers with AI associates), some get compressed (fewer junior roles), some get eliminated (first-level customer service). Understanding *which category your role falls into* matters more than understanding the overall trend.

**Financial moats still exist.** JPMorgan just released a list of 19 "AI-resistant" software stocks — companies with data gravity, compliance requirements, vertical lock-in, or security mandates that can't be vibe-coded away. The disruption is real, but it's not uniform.

**The capability-deployment gap is real.** Shumer focuses on what AI *can* do. But what it *will* do in organizations depends on procurement cycles, compliance reviews, integration costs, and human inertia. Enterprise adoption will lag capability by 18-36 months minimum.

## The Bottom Line

Matt Shumer wrote this article for his family and friends who keep asking "what's the deal with AI?" and getting the polite cocktail-party version. He decided they deserved the honest version, even if it sounds crazy.

Thirty-one million people read it. Ninety-two thousand bookmarked it.

The message is getting through. The question now is what you do with it.

---

**My advice, for what it's worth:**

1. **Pay for the frontier models.** $20/month for Claude Pro or ChatGPT Plus. Use the best available model, not the default. The gap between free and paid is enormous.

2. **Push it into your actual work.** Don't treat it like Google. Feed it your messy spreadsheets, your contracts, your analysis. See what happens.

3. **Build financial resilience.** Not panic, just options. Savings > fixed obligations. Flexibility > lock-in.

4. **Lean into what's hardest to replace.** Relationships. Trust built over years. Work that requires physical presence. Domain expertise in high-stakes, regulated environments.

The ground is shaking. The people close enough to feel it are trying to warn you.

Listen.

---

*Original article: [@mattshumer_](https://x.com/mattshumer_/status/2021256989876109403)*
